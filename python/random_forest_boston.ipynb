{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "random_forest_boston.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjDWv8anZ/Uw9XIkuLncAC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rich-descombaz/data-science/blob/master/python/random_forest_boston.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFvx1wtXUEWR",
        "colab_type": "text"
      },
      "source": [
        "Sample of running a random forest with Tensor Flow\n",
        "\n",
        "https://learning.oreilly.com/library/view/tensorflow-machine-learning/9781789131680/ca21cc12-2dc6-4f5d-859f-04a9c3ecaa0e.xhtml\n",
        "\n",
        "#Data from https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZVdnVBfTze6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.datasets import boston_housing\n",
        "from tensorflow.python.framework import ops\n",
        "ops.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En6szgHOT_ZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regression_classifier = tf.estimator.BoostedTreesRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMDpBFToUDtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC534xGZU02d",
        "colab_type": "code",
        "outputId": "7f6226fe-69eb-48eb-c961-e81aa3c87cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x_train[10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  9.59571,   0.     ,  18.1    ,   0.     ,   0.693  ,   6.404  ,\n",
              "       100.     ,   1.639  ,  24.     , 666.     ,  20.2    , 376.11   ,\n",
              "        20.31   ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_27Z3wBUnij",
        "colab_type": "text"
      },
      "source": [
        "Set model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zqgm-63Uki0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch size\n",
        "batch_size = 32\n",
        "# Number of training steps\n",
        "train_steps = 500\n",
        "# Number of trees in our 'forest'\n",
        "n_trees = 100\n",
        "# Maximum depth of any tree in forest\n",
        "max_depth = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc6yyUiaWwqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "binary_split_cols = ['CHAS', 'RAD']\n",
        "col_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
        "# for idx, col in enumerate(col_names) :\n",
        "#   print(\"{} = {}\".format(idx, col))\n",
        "#print(x_test[0:3, ])\n",
        "X_dtrain = {col: x_train[:, ix] for ix, col in enumerate(col_names)}\n",
        "#print(X_dtrain)\n",
        "X_dtest = {col: x_test[:, ix] for ix, col in enumerate(col_names)}\n",
        "#print(X_dtest)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kXOvp4mUrT2",
        "colab_type": "code",
        "outputId": "a98fcd3a-a5fe-4ba5-8fa1-414e71e7c972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "# Create feature columns!\n",
        "feature_cols = []\n",
        "for ix, column in enumerate(x_train.T):\n",
        "    col_name = col_names[ix]\n",
        "\n",
        "    # Create binary split feature\n",
        "    if col_name in binary_split_cols:\n",
        "        # To create 2 buckets, need 1 boundary - the mean\n",
        "        bucket_boundaries = [column.mean()]\n",
        "        print(bucket_boundaries)\n",
        "        numeric_feature = tf.feature_column.numeric_column(col_name)\n",
        "        final_feature = tf.feature_column.bucketized_column(source_column=numeric_feature, boundaries=bucket_boundaries)\n",
        "    # Create bucketed feature\n",
        "    else:\n",
        "        # To create 5 buckets, need 4 boundaries\n",
        "        bucket_boundaries = list(np.linspace(column.min() * 1.1, column.max() * 0.9, 4))\n",
        "        numeric_feature = tf.feature_column.numeric_column(col_name)\n",
        "        final_feature = tf.feature_column.bucketized_column(source_column=numeric_feature, boundaries=bucket_boundaries)\n",
        "\n",
        "    # Add feature to feature_col list\n",
        "    feature_cols.append(final_feature)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.06188118811881188]\n",
            "[9.44059405940594]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzoQef3-WvVb",
        "colab_type": "code",
        "outputId": "3f32b107-7f73-4b6e-d482-de2f86e0d1ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(bucket_boundaries)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.903, 12.659666666666668, 23.416333333333334, 34.173]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ7NWtuVeYLq",
        "colab_type": "code",
        "outputId": "0bd47f6e-ff0e-4cb9-df2c-fee37790d0b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "input_fun = tf.estimator.inputs.numpy_input_fn(X_dtrain, y=y_train, batch_size=batch_size,        num_epochs=150, shuffle=True)\n",
        "\n",
        "print(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[15.2 42.3 50.  21.1 17.7 18.5 11.3 15.6 15.6 14.4 12.1 17.9 23.1 19.9\n",
            " 15.7  8.8 50.  22.5 24.1 27.5 10.9 30.8 32.9 24.  18.5 13.3 22.9 34.7\n",
            " 16.6 17.5 22.3 16.1 14.9 23.1 34.9 25.  13.9 13.1 20.4 20.  15.2 24.7\n",
            " 22.2 16.7 12.7 15.6 18.4 21.  30.1 15.1 18.7  9.6 31.5 24.8 19.1 22.\n",
            " 14.5 11.  32.  29.4 20.3 24.4 14.6 19.5 14.1 14.3 15.6 10.5  6.3 19.3\n",
            " 19.3 13.4 36.4 17.8 13.5 16.5  8.3 14.3 16.  13.4 28.6 43.5 20.2 22.\n",
            " 23.  20.7 12.5 48.5 14.6 13.4 23.7 50.  21.7 39.8 38.7 22.2 34.9 22.5\n",
            " 31.1 28.7 46.  41.7 21.  26.6 15.  24.4 13.3 21.2 11.7 21.7 19.4 50.\n",
            " 22.8 19.7 24.7 36.2 14.2 18.9 18.3 20.6 24.6 18.2  8.7 44.  10.4 13.2\n",
            " 21.2 37.  30.7 22.9 20.  19.3 31.7 32.  23.1 18.8 10.9 50.  19.6  5.\n",
            " 14.4 19.8 13.8 19.6 23.9 24.5 25.  19.9 17.2 24.6 13.5 26.6 21.4 11.9\n",
            " 22.6 19.6  8.5 23.7 23.1 22.4 20.5 23.6 18.4 35.2 23.1 27.9 20.6 23.7\n",
            " 28.  13.6 27.1 23.6 20.6 18.2 21.7 17.1  8.4 25.3 13.8 22.2 18.4 20.7\n",
            " 31.6 30.5 20.3  8.8 19.2 19.4 23.1 23.  14.8 48.8 22.6 33.4 21.1 13.6\n",
            " 32.2 13.1 23.4 18.9 23.9 11.8 23.3 22.8 19.6 16.7 13.4 22.2 20.4 21.8\n",
            " 26.4 14.9 24.1 23.8 12.3 29.1 21.  19.5 23.3 23.8 17.8 11.5 21.7 19.9\n",
            " 25.  33.4 28.5 21.4 24.3 27.5 33.1 16.2 23.3 48.3 22.9 22.8 13.1 12.7\n",
            " 22.6 15.  15.3 10.5 24.  18.5 21.7 19.5 33.2 23.2  5.  19.1 12.7 22.3\n",
            " 10.2 13.9 16.3 17.  20.1 29.9 17.2 37.3 45.4 17.8 23.2 29.  22.  18.\n",
            " 17.4 34.6 20.1 25.  15.6 24.8 28.2 21.2 21.4 23.8 31.  26.2 17.4 37.9\n",
            " 17.5 20.   8.3 23.9  8.4 13.8  7.2 11.7 17.1 21.6 50.  16.1 20.4 20.6\n",
            " 21.4 20.6 36.5  8.5 24.8 10.8 21.9 17.3 18.9 36.2 14.9 18.2 33.3 21.8\n",
            " 19.7 31.6 24.8 19.4 22.8  7.5 44.8 16.8 18.7 50.  50.  19.5 20.1 50.\n",
            " 17.2 20.8 19.3 41.3 20.4 20.5 13.8 16.5 23.9 20.6 31.5 23.3 16.8 14.\n",
            " 33.8 36.1 12.8 18.3 18.7 19.1 29.  30.1 50.  50.  22.  11.9 37.6 50.\n",
            " 22.7 20.8 23.5 27.9 50.  19.3 23.9 22.6 15.2 21.7 19.2 43.8 20.3 33.2\n",
            " 19.9 22.5 32.7 22.  17.1 19.  15.  16.1 25.1 23.7 28.7 37.2 22.6 16.4\n",
            " 25.  29.8 22.1 17.4 18.1 30.3 17.5 24.7 12.6 26.5 28.7 13.3 10.4 24.4\n",
            " 23.  20.  17.8  7.  11.8 24.4 13.8 19.4 25.2 19.4 19.4 29.1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUetgklJiHSp",
        "colab_type": "code",
        "outputId": "dc3ce6d3-080d-4bc1-b0fc-b4b67c6fdd68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "model = regression_classifier(feature_columns=feature_cols,\n",
        "                              n_trees=n_trees,\n",
        "                              max_depth=max_depth,\n",
        "                              learning_rate=0.10,\n",
        "                              n_batches_per_layer=batch_size)\n",
        "model.train(input_fn=input_fun, steps=train_steps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmprast798n\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmprast798n', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7dde5c9c50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmprast798n/model.ckpt.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:loss = 549.7803, step = 0\n",
            "INFO:tensorflow:global_step/sec: 338.359\n",
            "INFO:tensorflow:loss = 442.18124, step = 100 (0.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 431.701\n",
            "INFO:tensorflow:loss = 186.23254, step = 200 (0.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 418.265\n",
            "INFO:tensorflow:loss = 90.760605, step = 300 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 415.283\n",
            "INFO:tensorflow:loss = 53.44664, step = 400 (0.240 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 500 into /tmp/tmprast798n/model.ckpt.\n",
            "WARNING:tensorflow:Issue encountered when serializing resources.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'_Resource' object has no attribute 'name'\n",
            "INFO:tensorflow:Loss for final step: 35.140553.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.boosted_trees.BoostedTreesRegressor object at 0x7f7dde5c97b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qj9fDNMiTVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCAqIQM7jNeV",
        "colab_type": "text"
      },
      "source": [
        "Evaluate Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0o6Ef-bjO5B",
        "colab_type": "code",
        "outputId": "0f033c3c-8d58-4b06-baa0-a09eafbfeaad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "p_input_fun = tf.estimator.inputs.numpy_input_fn(X_dtest, y=y_test, batch_size=batch_size, num_epochs=1, shuffle=False)\n",
        "# Get predictions\n",
        "predictions = list(model.predict(input_fn=p_input_fun))\n",
        "final_preds = [pred['predictions'][0] for pred in predictions]\n",
        "\n",
        "# Get accuracy (mean absolute error, MAE)\n",
        "mae = np.mean([np.abs((actual - predicted) / predicted) for actual, predicted in zip(y_test, final_preds)])\n",
        "print('Mean Abs Err on test set: {}'.format(mae))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmprast798n/model.ckpt-500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Mean Abs Err on test set: 0.3227831486197207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu3yQGcsjPcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}